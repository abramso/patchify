#! /usr/bin/env python
# Note that cfy is used rather than the client so that the user does not have
# to provide credentials, etc, to this script.
import argparse
from contextlib import contextmanager
import datetime
import json
import os
import subprocess
import sys
import tempfile
import time

BASE_MANAGER_PATCH_STORAGE_PATH = '/etc/cloudify/patches'
PATCH_REGISTRY_FILE_NAME = 'patch_registry.json'
PATCH_REGISTRY_PATH = os.path.join(
    BASE_MANAGER_PATCH_STORAGE_PATH, PATCH_REGISTRY_FILE_NAME
)


class VersionError(Exception):
    pass


class UploadError(Exception):
    pass


class DownloadError(Exception):
    pass


def exit_with_sadness(message, action):
    sadly_say(message)
    sadly_say('FAILED TO {action}!'.format(action=action))
    sys.exit(1)


def say(message):
    print(message)


def sadly_say(message):
    sys.stderr.write('%s\n' % message)


def get_manager_version():
    try:
        version_output = subprocess.check_output(['cfy', '--version'])
    except subprocess.CalledProcessError:
        return None

    community = 'Community edition' in version_output
    version = None

    for line in version_output.splitlines():
        if line.lower().startswith('cloudify manager'):
            # Expecting line to be similar to:
            # Cloudify Manager 4.2.0 [ip=10.239.3.199]
            version = line.split(' ')[2]
            break

    return {
        'version': version,
        'community': community,
        'raw': version_output,
    }


def parse_version_string(version):
    """
        Parse a version string in semantic versioning format.
    """
    version = version.split('.')

    if len(version) != 3:
        raise VersionError(
            'Version string must contain three components. '
            'Found: {split_version}'.format(
                split_version=version,
            ),
        )

    try:
        version = tuple(int(part) for part in version)
    except ValueError:
        raise VersionError(
            'Version string must contain only integer components. '
            'Found: {version}'.format(version=version),
        )

    return version


def load_patch_definition(filename):
    # TODO: Load the patch definition straight from the patch zip file
    with open(filename) as definition_handle:
        definition = json.load(definition_handle)

    # Currently this only handles version 1.0.0 of patch definitions:
    # {
    #   "patch_version": 1.0.0,  # No other value supported yet
    #   "manager_versions": [4.2],  # List of supported cloudify managers
    #   "community": <true|false>,  # Whether community is supported
    #   "premium": <true|false>,  # Whether premium is supported
    #   "patches": [  # List of patch files to apply.
    #                 # These should be in a format 'patch' on centos
    #                 # understands
    #     {
    #       "patch_file": "<patch file name in patch archive 'patches' dir>",
    #       "md5sum": "<md5sum of patch file>",
    #       "destinations": [  # List of locations that this file should patch
    #         "/path/to/location/on/manager",
    #         "/path/to/other/location/on/manager",
    #       ]
    #     },
    #     ... # More patch files, if any are required
    #   ],
    #   "affected_services": [  # List of services that will be stopped before
    #                           # applying the patches and started afterwards.
    #                           # These services will also be stopped before
    #                           # any rollbacks and started afterwards.
    #     "cloudify-service-1",
    #     "cloudify-service-2"
    #   ],
    #   # Following sections are optional, but recommended
    #   "md5sums_before": {  # Each file will have md5sum checked before
    #                        # applying the patches. If a file on the
    #                        # manager is specified in this list and does not
    #                        # have an md5sum in the acceptable list for that
    #                        # file, the patch process will be aborted.
    #                        # Files in this list will be backed up before the
    #                        # patch is applied, and restored if it aborts for
    #                        # any reason after the initial checks.
    #     "/path/to/file1": ["<md5sum before patch is applied>"],
    #     "/path/to/file2": ["<md5sum before patch is applied>"],
    #     "/path/to/file3": ["<md5sum before patch is applied>",
    #                        "<other acceptable md5sum>"]
    #   },
    #   "md5sums_after": {  # After all commands have been run, these md5sums
    #                       # will be checked after all patches have been
    #                       # applied and will abort and roll back the patch.
    #                       # While the list doesn't have to be the same, it
    #                       # probably should be, usually.
    #     "/path/to/file1": ["<md5sum after patch is applied>"],
    #     "/path/to/file2": ["<md5sum after patch is applied>"],
    #     "/path/to/file3": ["<md5sum after patch is applied>",
    #                        "<other acceptable md5sum>"]
    #   }
    # }
    try:
        patch_version = parse_version_string(definition['patch_version'])
    except KeyError:
        add_definition_error(
            message=(
                'patch_version not found in definition. '
                'Please confirm patch is valid and not corrupted.'
            ),
            definition=definition,
            fatal=True,
        )
        return definition

    if patch_version > (1, 0, 0):
        add_definition_error(
            message=(
                'Only version 1.0.0 patches are supported currently. '
                'Found version: {version}'.format(
                    version='.'.join([str(i) for i in patch_version]),
                )
            ),
            definition=definition,
            fatal=True,
        )
        return definition

    required_keys = ['manager_versions', 'community', 'premium']
    recommended_keys = []
    if patch_version[0] == 1:
        required_keys.extend(['patches', 'affected_services'])
        recommended_keys.extend(['md5sums_before', 'md5sums_after'])

    for key in required_keys:
        if key not in definition:
            add_definition_error(
                message=(
                    'Patch definition must contain {key}. '
                    'Keys found: {found}'.format(
                        key=key,
                        found=', '.join(definition.keys()),
                    )
                ),
                definition=definition,
                fatal=True,
            )

    for key in recommended_keys:
        if key not in definition:
            add_definition_error(
                message=(
                    'Patch definition should contain {key}. '
                    'Keys found: {found}'.format(
                        key=key,
                        found=', '.join(definition.keys()),
                    )
                ),
                definition=definition,
            )

    return definition


def load_and_validate_patch_definition(filename, action):
    definition = load_patch_definition(filename)

    fatal_error = False
    for error in definition.get('errors', []):
        message = error['message']
        if error['fatal']:
            message = 'FATAL: ' + message
            fatal_error = True
        sadly_say(message)
    if fatal_error:
        exit_with_sadness('Patch definition error!', action)

    return definition


def add_definition_error(message, definition, fatal=False):
    errors = definition.get('errors', [])
    errors.append({
        'message': message,
        'fatal': fatal,
    })
    definition['errors'] = errors


def get_unhealthy_services():
    try:
        status_output = subprocess.check_output(['cfy', 'status'])
    except subprocess.CalledProcessError:
        return ['All processes (is cfy pointing at a working manager?)']

    unhealthy_services = []

    dividers_found = 0
    for line in status_output.splitlines():
        if dividers_found == 3:
            # We reached the end of the output
            break

        line = line.strip()

        # Expecting something like:
        # Getting management services status... [ip=192.0.2.4]
        #
        # Services:
        # +--------------------------------+--------+
        # |            service             | status |
        # +--------------------------------+--------+
        # | Riemann                        |   up   |
        # | Celery Management              |   up   |
        # | Manager Rest-Service           |   up   |
        # | AMQP InfluxDB                  |   up   |
        # | RabbitMQ                       |   up   |
        # | Elasticsearch                  |   up   |
        # | Webserver                      |   up   |
        # | Logstash                       |   up   |
        # +--------------------------------+--------+
        if line.startswith('+--'):
            dividers_found += 1
        elif dividers_found == 2:
            # Services are only shown after the second divider
            line = line.split('|')
            service = line[1].strip()
            status = line[2].strip()
            if status not in ('running', 'up'):
                unhealthy_services.append(service)

    return unhealthy_services


def get_file_md5sum(file_path, manager_connection_string, keyfile):
    # Structure the command so that we return meaningful output in predictable
    # situations (where the path isn't a file (e.g. is a directory) or does
    # not exist), while still allowing failure for unexpected situations
    # (e.g. segfault on one of the commands)
    md5command = (
        'if [[ -f {path} ]]; '
        # sudo this so that we can avoid permissions issues
        '  then sudo md5sum {path}; '
        'elif [[ -e {path} ]]; '
        '  then echo -n "{notafile}"; '
        'else '
        '  echo -n "{notexisting}"; '
        'fi'.format(
            path=file_path,
            notafile="NOTAFILE",
            notexisting="DOESNOTEXIST",
        )
    )
    return ssh(manager_connection_string, keyfile, md5command).split(' ')[0]


def get_local_md5sum(file_path):
    return subprocess.check_output(['md5sum', file_path]).split(' ')[0]


def md5sums_match(check_list, manager_connection_string, keyfile):
    matching = True
    for file_path, acceptable_md5sums in check_list.items():
        say('Checking md5sum for {path}'.format(path=file_path))
        md5sum = get_file_md5sum(file_path, manager_connection_string, keyfile)

        if md5sum not in acceptable_md5sums:
            matching = False
            if acceptable_md5sums == ["DOESNOTEXIST"]:
                message = (
                    '{file_path} should not exist, but file with md5sum '
                    '{md5sum} was found.'
                )
            else:
                message = (
                    '{file_path} has an incorrect md5sum. '
                    'md5sum was {md5sum}. '
                    'Allowed md5sums are {acceptable}'
                )

            sadly_say(message.format(
                file_path=file_path,
                md5sum=md5sum,
                acceptable=', '.join(acceptable_md5sums),
            ))

    return matching


def can_ssh(manager_connection_string, keyfile):
    try:
        ssh(manager_connection_string, keyfile, 'echo "SSH works."')
        return True
    except subprocess.CalledProcessError:
        return False


def patch_command_available(manager_connection_string, keyfile):
    try:
        ssh(manager_connection_string, keyfile, 'which patch')
        return True
    except subprocess.CalledProcessError:
        return False


def ssh(manager_connection_string, keyfile, command):
    ssh_command = ['ssh']
    if keyfile:
        ssh_command.extend(['-i', keyfile])
    ssh_command.extend([manager_connection_string, command])
    return subprocess.check_output(ssh_command)


@contextmanager
def temporarily_own_directory(manager_connection_string, keyfile, path):
    ssh(
        manager_connection_string,
        keyfile,
        'sudo chown $(whoami). ' + path,
    )
    try:
        yield
    finally:
        ssh(
            manager_connection_string,
            keyfile,
            'sudo chown root. ' + path,
        )


def _scp(keyfile, source, dest, quiet=False):
    scp_command = ['scp']
    if keyfile:
        scp_command.extend(['-i', keyfile])
    scp_command.extend([source, dest])
    if quiet:
        subprocess.check_output(scp_command)
    else:
        subprocess.check_call(scp_command)


def upload(file_name, source_path, dest_path,
           manager_connection_string, keyfile,
           expected_md5sum=None):
    source = os.path.join(source_path, file_name)
    dest = '{mgr}:{dest_path}'.format(
        mgr=manager_connection_string,
        dest_path=dest_path,
    )
    say("Uploading {source} to {dest}".format(source=source, dest=dest))

    _scp(keyfile, source, dest)

    if not expected_md5sum:
        expected_md5sum = get_local_md5sum(source)

    uploaded_md5sum = get_file_md5sum(
        file_path=dest_path,
        manager_connection_string=manager_connection_string,
        keyfile=keyfile,
    )

    if not uploaded_md5sum == expected_md5sum:
        raise UploadError(
            'Uploaded file {file_name} had md5sum {actual}, but should '
            'have had {expected}.'.format(
                file_name=file_name,
                actual=uploaded_md5sum,
                expected=expected_md5sum,
            )
            )


def download(file_name, source_path, dest_path,
             manager_connection_string, keyfile, quiet=False):
    source = '{mgr}:{dest_path}'.format(
        mgr=manager_connection_string,
        dest_path=os.path.join(source_path, file_name),
    )
    dest = dest_path
    if not quiet:
        say("Downloading {source} to {dest}".format(source=source, dest=dest))

    _scp(keyfile, source, dest, quiet=quiet)

    original_md5sum = get_file_md5sum(
        file_path=os.path.join(source_path, file_name),
        manager_connection_string=manager_connection_string,
        keyfile=keyfile,
    )

    downloaded_md5sum = get_local_md5sum(dest)

    if not original_md5sum == downloaded_md5sum:
        raise DownloadError(
            'Downloaded file {file_path} had md5sum {actual}, but should '
            'have had {expected}.'.format(
                file_path=os.path.join(dest_path, file_name),
                actual=downloaded_md5sum,
                expected=original_md5sum,
            )
        )


def stop_services(manager_connection_string, services, keyfile):
    for service in services:
        ssh(
            manager_connection_string,
            keyfile,
            'sudo systemctl stop {service}'.format(service=service),
        )


def start_services(manager_connection_string, services, keyfile):
    # Ensure we're using any unit files we may have updated
    ssh(
        manager_connection_string,
        keyfile,
        'sudo systemctl daemon-reload',
    )
    for service in services:
        ssh(
            manager_connection_string,
            keyfile,
            'sudo systemctl start {service}'.format(service=service),
        )


def upload_and_verify_patch_files(manager_connection_string, patch_dir,
                                  patches, staging_dir, keyfile):
    for patch in patches:
        patch_name = patch['patch_file']
        expected_md5sum = patch['md5sum']

        upload(
            file_name=patch_name,
            source_path=patch_dir,
            dest_path=os.path.join(staging_dir, patch_name),
            expected_md5sum=expected_md5sum,
            manager_connection_string=manager_connection_string,
            keyfile=keyfile,
        )


def build_manager_version_output_string(version, community):
    version_output = version
    if community:
        version_output += ' community'
    else:
        version_output += ' premium'
    return version_output


def rollback(manager_connection_string, patch_definition, backup_root,
             delete_root, keyfile, skip_services):
    if skip_services:
        sadly_say(
            "Not ensuring services are stopped due to skip-services flag."
        )
    else:
        # Make sure all services are stopped, which might not be the case
        # depending on when we had to begin the rollback.
        sadly_say('Ensuring services are stopped for rollback.')
        stop_services(
            manager_connection_string,
            patch_definition['affected_services'],
            keyfile,
        )

    sadly_say('Rolling back file changes.')
    affected_files = get_list_of_affected_files(patch_definition['patches'])
    for affected_file in affected_files:
        backed_up_file = os.path.join(
            backup_root,
            affected_file.lstrip('/'),
        )
        delete_dest_parent = os.path.join(
            delete_root,
            os.path.split(affected_file.lstrip('/'))[0]
        )
        delete_dest = os.path.join(
            delete_root,
            affected_file.lstrip('/')
        )
        ssh(
            manager_connection_string,
            keyfile,
            'if sudo test -f {backup}; then '    # Only restore existing
            '  sudo cp {backup} {orig}; '        # and remove added files
            'else '
            '  sudo mkdir -p {delete_dest_parent} && '
            '  sudo mv {orig} {delete_dest}; '
            'fi'.format(
                backup=backed_up_file,
                orig=affected_file,
                delete_dest_parent=delete_dest_parent,
                delete_dest=delete_dest,
            ),
        )

    if skip_services:
        sadly_say("Not restarting services due to skip-services flag.")
    else:
        sadly_say('Starting services after rollback.')
        start_services(
            manager_connection_string,
            patch_definition['affected_services'],
            keyfile,
        )

    # TODO: We should check service state here

    sadly_say('Rollback complete.')


def get_list_of_affected_files(patches):
    affected_files = []
    for patch in patches:
        affected_files.extend(patch['destinations'])
    return set(affected_files)


def get_patch_storage_path(timestamp):
    # Don't use os.path.join in case this gets run on windows (the path itself
    # is on the manager, which will be Linux)
    return '{base}/{timestamp}'.format(
        base=BASE_MANAGER_PATCH_STORAGE_PATH,
        timestamp=timestamp,
    )


def abort_on_ssh_failure(manager_connection_string, keyfile, action,
                         quiet=False):
    if not quiet:
        say("Checking SSH.")
    if not can_ssh(manager_connection_string, keyfile):
        exit_with_sadness(
            'Failed to SSH into manager.', action,
        )


def apply_patch(definition_file, manager_connection_string, keyfile,
                skip_services, install_patch_command):
    action = 'APPLY PATCH'

    say("Loading patch definition.")
    patch_definition = load_and_validate_patch_definition(definition_file,
                                                          action)

    patch_name = os.path.basename(definition_file)
    if patch_name.endswith('.json'):
        # Remove patch name extension
        patch_name = os.path.splitext(patch_name)[0]

    fatal_error = False
    for error in patch_definition.get('errors', []):
        message = error['message']
        if error['fatal']:
            message = 'FATAL: ' + message
            fatal_error = True
        sadly_say(message)
    if fatal_error:
        exit_with_sadness('Patch definition error!')

    say("Checking manager version is valid.")
    manager_version = get_manager_version()
    raw_version_output = manager_version.pop('raw')
    if manager_version is None:
        exit_with_sadness(
            'Could not get manager version! '
            'Are you in an environment with cfy using a profile for the '
            'manager you intend to patch?',
            action,
        )
    supported_versions = []
    if patch_definition['premium']:
        for version in patch_definition['manager_versions']:
            supported_versions.append({
                'version': version,
                'community': False,
            })
    if patch_definition['community']:
        for version in patch_definition['manager_versions']:
            supported_versions.append({
                'version': version,
                'community': True,
            })
    if manager_version not in supported_versions:
        manager_version_output = manager_version['version']
        try:
            manager_version_output = build_manager_version_output_string(
                version=manager_version['version'],
                community=manager_version['community'],
            )
        except Exception:
            exit_with_sadness(
                'Could not determine manager version.\n'
                'Version check output was: {raw_output}'.format(
                    raw_output=raw_version_output,
                ),
                action,
            )
        supported_versions_output = ', '.join([
            build_manager_version_output_string(
                version=version['version'],
                community=version['community'],
            )
            for version in supported_versions
        ])
        exit_with_sadness(
            'Manager version mismatch. '
            'Manager is {manager_version}, but patch only supports '
            '{supported_versions}'.format(
                manager_version=manager_version_output,
                supported_versions=supported_versions_output,
            ),
            action,
        )

    say("Checking service state.")
    unhealthy_services = get_unhealthy_services()
    if unhealthy_services:
        exit_with_sadness(
            'Not all services are healthy. '
            'Unhealthy services: {services}'.format(
                services=', '.join(unhealthy_services),
            ),
            action,
        )

    abort_on_ssh_failure(manager_connection_string, keyfile, action)

    say('Confirming patch command exists on server.')
    if not patch_command_available(manager_connection_string, keyfile):
        if install_patch_command:
            say("Patch command not found. Installing patch command.")
            ssh(
                manager_connection_string,
                keyfile,
                'sudo yum install -y patch',
            )
        else:
            exit_with_sadness(
                'Could not find "patch" command on server. '
                'On the manager, you may need to run: '
                '"sudo yum install -y patch" or call this script with '
                'the --install-patch-command flag.',
                action,
            )

    say("Checking md5sums are as expected.")
    if not md5sums_match(patch_definition['md5sums_before'],
                         manager_connection_string,
                         keyfile):
        exit_with_sadness(
            'Unexpected md5sums found before starting patch installation.',
            action,
        )

    say("Retrieving patch registry information.")
    registry = download_patch_registry(manager_connection_string, keyfile,
                                       action)

    # Avoiding : in timestamp to avoid needing to escape it for bash
    timestamp = datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S%z')
    say("Patching timestamp is: {timestamp}".format(timestamp=timestamp))
    patch_path = get_patch_storage_path(timestamp)

    say("Creating patch directory in: {path}".format(path=patch_path))
    # We will also put some patch details to aid any later troubleshooting
    patch_info = 'attempting to apply ' + patch_name
    ssh(
        manager_connection_string,
        keyfile,
        'sudo mkdir -p ' + patch_path +
        ' && echo ' + patch_info +
        ' | sudo tee ' + patch_path + '/patch_info >/dev/null',
    )
    with temporarily_own_directory(manager_connection_string, keyfile,
                                   patch_path):
        source_path, file_name = os.path.split(definition_file)
        upload(
            file_name=file_name,
            source_path=source_path,
            dest_path=os.path.join(patch_path, 'patch_definition'),
            manager_connection_string=manager_connection_string,
            keyfile=keyfile,
        )

    backup_root = '{base}/backups'.format(
        base=patch_path,
    )
    delete_root = '{base}/deleted_files'.format(
        base=patch_path,
    )
    say("Backing up affected files to {path}".format(path=backup_root))
    ssh(
        manager_connection_string,
        keyfile,
        'sudo mkdir -p ' + backup_root,
    )
    ssh(
        manager_connection_string,
        keyfile,
        'sudo mkdir -p ' + delete_root,
    )
    affected_files = get_list_of_affected_files(patch_definition['patches'])
    for affected_file in affected_files:
        say(
            "Backing up {file_path} to {destination}".format(
                file_path=affected_file,
                destination=os.path.join(
                    backup_root,
                    affected_file.lstrip('/'),
                ),
            )
        )
        # We sudo (root) the copy because of user differences in different
        # versions of cloudify, but we probably should define this better
        # based on which version it's targetting.
        ssh(
            manager_connection_string,
            keyfile,
            'if sudo test -f {source}; then '  # Only if the file exists
            'sudo cp --parents {source} {destination}; fi'.format(
                source=affected_file,
                destination=backup_root,
            ),
        )

    staging_dir = '{base}/patch_files'.format(
        base=patch_path,
    )
    ssh(
        manager_connection_string,
        keyfile,
        'sudo mkdir -p ' + staging_dir,
    )
    with temporarily_own_directory(manager_connection_string, keyfile,
                                   staging_dir):
        patch_dir = os.path.join(os.path.dirname(definition_file), 'patches')
        say("Uploading and verifying patch files.")
        try:
            upload_and_verify_patch_files(manager_connection_string,
                                          patch_dir,
                                          patch_definition['patches'],
                                          staging_dir,
                                          keyfile)
        except UploadError as err:
            exit_with_sadness(
                'Failed to upload patch files: {err}'.format(
                    err=str(err),
                ),
                action,
            )

    if skip_services:
        say("Not stopping services due to skip-services flag.")
    else:
        say("Stopping services.")
        stop_services(manager_connection_string,
                      patch_definition['affected_services'],
                      keyfile)

    say("Applying patches.")
    for patch in patch_definition['patches']:
        for destination in patch['destinations']:
            say(
                'Applying {patch} to {target}'.format(
                    patch=patch['patch_file'],
                    target=destination,
                )
            )
            try:
                ssh(
                    manager_connection_string,
                    keyfile,
                    'sudo patch {destination} {patch}'.format(
                        destination=destination,
                        patch=os.path.join(
                            staging_dir,
                            patch['patch_file'],
                        ),
                    )
                )
            except subprocess.CalledProcessError as err:
                rollback(manager_connection_string, patch_definition,
                         backup_root, delete_root, keyfile, skip_services)
                exit_with_sadness(
                    'Failed to apply patch {patch} to {target}\n'
                    'Changes rolled back.'.format(
                        patch=patch['patch_file'],
                        target=destination,
                    ),
                    action,
                )

    say("Checking post-patch md5sums.")
    if not md5sums_match(patch_definition['md5sums_after'],
                         manager_connection_string,
                         keyfile):
        rollback(manager_connection_string, patch_definition, backup_root,
                 delete_root, keyfile, skip_services)
        exit_with_sadness(
            'Unexpected md5sums found after patch installation.\n'
            'Changes rolled back.',
            action,
        )

    if skip_services:
        say("Not starting services due to skip-services flag.")
    else:
        say("Starting services.")
        start_services(manager_connection_string,
                       patch_definition['affected_services'],
                       keyfile)

    say("Checking service state with patches applied.")
    unhealthy_services = []
    for attempt in range(0, 10):
        if unhealthy_services:
            say("Services still restarting...")
            time.sleep(3)
        unhealthy_services = get_unhealthy_services()
    if unhealthy_services:
        rollback(manager_connection_string, patch_definition, backup_root,
                 delete_root, keyfile, skip_services)
        exit_with_sadness(
            'Services did not restart correctly. '
            'Unhealthy services: {services}\n'
            'Changes rolled back.'.format(
                services=', '.join(unhealthy_services),
            ),
            action,
        )
    say("Patch installed and services healthy.")

    say("Updating patch information and registry.")
    patch_info = "applied " + patch_name
    ssh(
        manager_connection_string,
        keyfile,
        'echo ' + patch_info +
        ' | sudo tee ' + patch_path + '/patch_info >/dev/null',
    )
    add_patch_to_registry(registry, timestamp,
                          patch_name, patch_path, patch_definition,
                          manager_connection_string, keyfile,
                          action)

    say('Patch applied!')


def add_patch_to_registry(registry, timestamp,
                          patch_name, patch_path, patch_definition,
                          manager_connection_string, keyfile,
                          action):
    current_patches = registry.get('current_patches', [])

    affected_files = patch_definition['md5sums_after'].keys()

    block_uninstall = []
    for existing_patch in current_patches:
        if any(affected_file in existing_patch['modified_files']
               for affected_file in affected_files):
            block_uninstall.append(existing_patch['patch_id'])

    definition_md5sum = get_file_md5sum(
        file_path=os.path.join(patch_path, 'patch_definition'),
        manager_connection_string=manager_connection_string,
        keyfile=keyfile,
    )

    new_patch = {
        'patch_id': patch_name + '-' + definition_md5sum,
        'patch_name': patch_name,
        'timestamp': timestamp,
        'patch_directory': patch_path,
        'modified_files': patch_definition['md5sums_after'],
        'blocks_uninstall_of': block_uninstall,
    }

    current_patches.append(new_patch)

    registry['current_patches'] = current_patches

    tmp_path = tempfile.mkdtemp(prefix='patchify-')
    local_reg_path = os.path.join(tmp_path, PATCH_REGISTRY_FILE_NAME)

    try:
        with open(local_reg_path, 'w') as local_reg_handle:
            local_reg_handle.write(json.dumps(registry))
    except Exception as err:
        exit_with_sadness(
            'FAILED TO GENERATE NEW REGISTRY!\n'
            'PATCH HAS BEEN APPLIED BUT REGISTRY IS INCORRECT!\n'
            'Error was: {err}'.format(err=err),
            action,
        )

    with temporarily_own_directory(manager_connection_string, keyfile,
                                   BASE_MANAGER_PATCH_STORAGE_PATH):
        upload(
            file_name=PATCH_REGISTRY_FILE_NAME,
            source_path=tmp_path,
            dest_path=PATCH_REGISTRY_PATH,
            manager_connection_string=manager_connection_string,
            keyfile=keyfile,
        )

    os.unlink(local_reg_path)
    os.rmdir(tmp_path)


def get_uninstall_blockers(patches):
    blockers = {}
    for patch in patches:
        for blocked in patch.get('blocks_uninstall_of', []):
            if blocked not in blockers:
                blockers[blocked] = []
            blockers[blocked].append(patch['patch_id'])
    return blockers


def list_patches(manager_connection_string, keyfile, json_output):
    action = 'LIST PATCHES'

    if not json_output:
        say("Getting installed patch details from manager...")
    abort_on_ssh_failure(manager_connection_string, keyfile, action,
                         quiet=json_output)
    registry = download_patch_registry(manager_connection_string, keyfile,
                                       action, quiet=json_output)
    patches = registry.get('current_patches', [])

    if json_output:
        say(json.dumps(patches))
    else:
        if patches:
            uninstall_blocked = get_uninstall_blockers(patches)
            for patch in patches:
                if patch['patch_id'] in uninstall_blocked:
                    uninstall_restrictions = (
                        ' Uninstall blocked by: {blockers}'.format(
                            blockers=', '.join(
                                uninstall_blocked[patch['patch_id']]
                            ),
                        )
                    )
                else:
                    uninstall_restrictions = ''

                say(
                    'Patch {name} (ID: {patch_id}) was installed on '
                    '{timestamp}.{uninstall_restrictions}'.format(
                        name=patch['patch_name'],
                        patch_id=patch['patch_id'],
                        timestamp=patch['timestamp'],
                        uninstall_restrictions=uninstall_restrictions,
                    )
                )
        else:
            say("No installed patches found on manager.")


def download_patch_registry(manager_connection_string, keyfile, action,
                            quiet=False):
    patch_registry_md5 = get_file_md5sum(
        PATCH_REGISTRY_PATH,
        manager_connection_string,
        keyfile,
    )
    if patch_registry_md5 == 'DOESNOTEXIST':
        registry = {
            'current_patches': [],
        }
    else:
        tmp_path = tempfile.mkdtemp(prefix='patchify-')
        local_reg_path = os.path.join(tmp_path, PATCH_REGISTRY_FILE_NAME)

        download(
            file_name=PATCH_REGISTRY_FILE_NAME,
            source_path=BASE_MANAGER_PATCH_STORAGE_PATH,
            dest_path=local_reg_path,
            manager_connection_string=manager_connection_string,
            keyfile=keyfile,
            quiet=quiet,
        )

        try:
            with open(local_reg_path) as local_reg_handle:
                registry = json.load(local_reg_handle)
        except ValueError:
            exit_with_sadness(
                'Could not parse existing patch registry.',
                action,
            )
        finally:
            os.unlink(local_reg_path)
            os.rmdir(tmp_path)
    return registry


def add_default_args(parser):
    parser.add_argument(
        '-c', '--manager_connection_string',
        help="The manager connection string for ssh, e.g. centos@192.0.2.4",
        required=True,
    )
    parser.add_argument(
        '-i', '--keyfile',
        help=(
            'The path to the ssh keyfile to use. If not set, no keyfile will '
            'be specified.'
        ),
        default=None,
        required=False,
    )


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Apply a patch to a cloudify manager.',
    )
    # TODO: We should probably want the patch supplied as a zip containing
    # the patch definition and the patch file, but for POC purposes we just
    # put everything in the POC folder

    subparsers = parser.add_subparsers(help='Patch action',
                                       dest='action')

    list_patch_args = subparsers.add_parser('list',
                                            help='List installed patches')
    list_patch_args.add_argument(
        '-j', '--json',
        help=(
            'Whether to output the patch list in json. '
            'If true, a json dict mapping timestamps to patch names will be '
            'the output.'
        ),
        action='store_true',
        default=False,
        required=False,
    )
    add_default_args(list_patch_args)

    apply_patch_args = subparsers.add_parser('apply',
                                             help='Apply a patch')
    apply_patch_args.add_argument(
        '-s', '--skip-services',
        help=(
            'Set this flag to not restart services. This is only to be used '
            'when instructed by Cloudify support.'
        ),
        action='store_true',
        default=False,
        required=False,
    )
    apply_patch_args.add_argument(
        '-p', '--patch_file',
        help=(
            'The patch file to use. Note that for POC purposes this is just '
            'a definition file, but this should probably be changed to a zip '
            'for real world use (so that it can work on Windows as well as '
            'Linux.'
        ),
        required=True,
    )
    apply_patch_args.add_argument(
        '-P', '--install-patch-command',
        help=(
            'Set this flag to yum install the patch command if it is not '
            'present.'
        ),
        action='store_true',
        default=False,
        required=False,
    )
    add_default_args(apply_patch_args)

    args = parser.parse_args()

    if args.action == 'apply':
        apply_patch(args.patch_file, args.manager_connection_string,
                    args.keyfile, args.skip_services,
                    args.install_patch_command)
    elif args.action == 'list':
        list_patches(args.manager_connection_string, args.keyfile, args.json)
    else:
        # You can't get here without messing about with the code above
        raise RuntimeError('Invalid action specified in parser.')
